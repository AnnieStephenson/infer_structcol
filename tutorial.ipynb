{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for infer_structcol package\n",
    "\n",
    "This tutorial explains how to use the infer_structcol package to infer the volume fraction of a structurally colored sample using experimental reflectance and transmittance data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "# import package\n",
    "import infer_structcol as ifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 10                                    # number of walkers to step through different parameters\n",
    "nsteps = 100                                    # number of steps for each walker to take\n",
    "particle_radius = 119                           # radius of colloidal particles in the colloidal glass (in nm)\n",
    "thickness = 120                                 # thickness of colloidal glass film (in um)\n",
    "particle_index = 1.59                           # refractive index of colloidal particles \n",
    "matrix_index = 1                                # refractive index of matrix material surrounding particles\n",
    "wavelengths = [450,500,550,600,650,700,750,800] # wavelengths of interest where spectrum should be calculated (in nm)\n",
    "\n",
    "# Initial guess for the parameters to be inferred: theta_guess = (volume fraction, loss intercept for reflectance, \n",
    "# loss slope for reflectance, loss intercept for transmittance, loss slope for transmittance). If only reflectance or \n",
    "# transmittance data are used, then theta_guess = (volume fraction, loss intercept, loss slope). \n",
    "theta_guess = (0.59, 0.5, 0, 0.5, 0)\n",
    "directory = os.path.join('infer_structcol','tests','test_data','experimental_data')\n",
    "#directory = 'infer_structcol'                   # path where the data is found\n",
    "refl_reference_file = 'R_ref.txt'                      # name of reference file for reflectance data\n",
    "refl_dark_file = 'R_dark.txt'                          # name of dark file for reflectance data\n",
    "trans_reference_file = 'T_ref.txt'                      # name of reference file for transmittance data\n",
    "trans_dark_file = 'T_dark.txt'                          # name of dark file for transmittance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer parameters\n",
    "##### Convert raw data into a normalized spectrum and load it\n",
    "All data files for transmission (including reference and dark measurements) should be located in a directory called 'transmission', and all data files for reflection should be located in a directory called 'reflection'. They should be .txt files with two $\\textit{tab-separated}$ columns, where the first is the wavelength and the second is the reflectance or transmittance fraction. Any header information at the top or bottom of the file will be ignored. The reference and dark spectra should have unique names as specified by the user, and the transmission or reflection spectra can have any unspecified name. The code will assume that any file in the data directory other than the reference or dark files is a transmittance or reflectance spectrum. It is expected that the user will include several reflectance/transmittance measurements of the same sample in order to calculate an uncertainty on the data. \n",
    "\n",
    "The data must first be converted into a normalized spectrum with values from 0 to 1, using the reference and dark spectra. This is accomplished using the convert_data() function. The converted data consists of a file with 3 columns: wavelength, normalized intensity, and uncertainty. The uncertainty is the sample standard deviation calculated from all of the reflectance/transmittance data in the directory.\n",
    "\n",
    "The converted data must then be loaded using the load_spectrum() function. This function selects the first reflectance and transmittance data set and returns a Spectrum class object, which containts the relevant spectrum data as a Pandas dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a converted data file for transmittance and reflectance spectra in the directory\n",
    "ifs.convert_data(wavelengths, refl_reference_file, refl_dark_file, os.path.join(directory, 'reflection'))\n",
    "ifs.convert_data(wavelengths, trans_reference_file, trans_dark_file, os.path.join(directory, 'transmission'))\n",
    "\n",
    "# load the converted data file as a Spectrum object\n",
    "spect = ifs.load_spectrum(refl_filepath = os.path.join(directory, 'reflection', 'converted', '0_data_file.txt'), \n",
    "                          trans_filepath = os.path.join(directory, 'transmission', 'converted', '0_data_file.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define sample object\n",
    "This object contains the parameters relevant to the colloidal glass sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp = ifs.Sample(spect.wavelength, particle_radius, thickness, particle_index, matrix_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform inference calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN value of lnprob for parameters: \n",
      "[ 0.38426269  0.68648775 -0.19723877  0.68648775 -0.19723877]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "lnprob returned NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8008e2d4330a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# run the markov chain monte carlo calculation to step through different values of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# parameters and infer the most likely values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwalkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnwalkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_guess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print the time the calculation took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vhwang/Documents/Harvard/PHY201/Final_project/infer_structcol-master/infer_structcol/inference.py\u001b[0m in \u001b[0;36mrun_mcmc\u001b[0;34m(data, sample, nwalkers, nsteps, theta, seed)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memcee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnsembleSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnwalkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vhwang/anaconda/lib/python3.5/site-packages/emcee/sampler.py\u001b[0m in \u001b[0;36mrun_mcmc\u001b[0;34m(self, pos0, N, rstate0, lnprob0, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         for results in self.sample(pos0, lnprob0, rstate0, iterations=N,\n\u001b[0;32m--> 172\u001b[0;31m                                    **kwargs):\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vhwang/anaconda/lib/python3.5/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, p0, lnprob0, rstate0, blobs0, iterations, thin, storechain, mh_proposal)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mS0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     q, newlnp, acc, blob = self._propose_stretch(p[S0], p[S1],\n\u001b[0;32m--> 259\u001b[0;31m                                                                  lnprob[S0])\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                         \u001b[0;31m# Update the positions, log probabilities and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vhwang/anaconda/lib/python3.5/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36m_propose_stretch\u001b[0;34m(self, p0, p1, lnprob0)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Calculate the proposed positions and the log-probability there.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnewlnprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lnprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Decide whether or not the proposals should be accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vhwang/anaconda/lib/python3.5/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36m_get_lnprob\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;31m# Finally raise exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lnprob returned NaN.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlnprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: lnprob returned NaN."
     ]
    }
   ],
   "source": [
    "# time the calculation, if desired\n",
    "t0 = time.time()\n",
    "\n",
    "# run the markov chain monte carlo calculation to step through different values of \n",
    "# parameters and infer the most likely values\n",
    "walkers = ifs.run_mcmc(spect, samp, nwalkers, nsteps, theta_guess, seed=2)\n",
    "\n",
    "# print the time the calculation took\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "If you want to have these results for later, you can save the markov chains for each parameter as a text file with a desired name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('walkers_chain_vf_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,0])\n",
    "np.savetxt('walkers_chain_refl_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,1])\n",
    "np.savetxt('walkers_chain_refl_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,2])\n",
    "np.savetxt('walkers_chain_trans_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,3])\n",
    "np.savetxt('walkers_chain_trans_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "##### Load the data\n",
    "Load the data that you saved to a text file previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vf = np.loadtxt('walkers_chain_vf_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "refl_l0 = np.loadtxt('walkers_chain_refl_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "refl_l1 = np.loadtxt('walkers_chain_refl_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "trans_l0 = np.loadtxt('walkers_chain_trans_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "trans_l1 = np.loadtxt('walkers_chain_trans_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the traces\n",
    "Plot the values for the loss parameters and the volume fraction at each step of the Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax_vf, ax_refl_l1, ax_refl_l0, ax_trans_l0, ax_trans_l1) = plt.subplots(3)\n",
    "ax_vf.set(ylabel='volume fraction')\n",
    "ax_refl_l0.set(ylabel='reflectance l_0')\n",
    "ax_refl_l1.set(ylabel='reflectance l_1')\n",
    "ax_trans_l0.set(ylabel='transmittance l_0')\n",
    "ax_trans_l1.set(ylabel='transmittance l_1')\n",
    "\n",
    "for i in range(nwalkers):\n",
    "    sns.tsplot(vf[i,:], ax=ax_vf)\n",
    "    sns.tsplot(refl_l0[i,:], ax=ax_refl_l0)\n",
    "    sns.tsplot(refl_l1[i,:], ax=ax_refl_l1)\n",
    "    sns.tsplot(trans_l0[i,:], ax=ax_trans_l0)\n",
    "    sns.tsplot(trans_l1[i,:], ax=ax_trans_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimate the most likely volume fraction\n",
    "\n",
    "The most likely volume fraction is found by calculating the median value of the volume fraction traces after cutting off the burn-in time. We calculate a 68% confidence interval using the built-in numpy percentile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trim off the burn in time, which we observe from the plots above\n",
    "trim_index = 50\n",
    "vf = np.ndarray.flatten(vf[:,trim_index:])\n",
    "\n",
    "# find the median of the volume fractions of the walkers\n",
    "vf_inferred = np.median(vf)\n",
    "print(\"The inferred volume fraction is {:.3f} + {:.3f} - {:.3f}\".format(vf_inferred,\n",
    "                                                                       np.percentile(vf,84)-vf_inferred,\n",
    "                                                                       vf_inferred - np.percentile(vf,16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
