{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for infer_structcol package\n",
    "\n",
    "This tutorial explains how to use the infer_structcol package to infer the volume fraction of a structurally colored sample using experimental reflectance and transmittance data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "# import package\n",
    "import infer_structcol as ifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 6                                    # number of walkers to step through different parameters\n",
    "nsteps = 100                                    # number of steps for each walker to take\n",
    "particle_radius = 119                           # radius of colloidal particles in the colloidal glass (in nm)\n",
    "thickness = 120                                 # thickness of colloidal glass film (in um)\n",
    "particle_index = 1.59                           # refractive index of colloidal particles \n",
    "matrix_index = 1                                # refractive index of matrix material surrounding particles\n",
    "wavelengths = [450,500,550,600,650,700,750,800] # wavelengths of interest where spectrum should be calculated (in nm)\n",
    "\n",
    "# Initial guess for the parameters to be inferred: theta_guess = (volume fraction, loss intercept for reflectance, \n",
    "# loss slope for reflectance, loss intercept for transmittance, loss slope for transmittance). If only reflectance or \n",
    "# transmittance data are used, then theta_guess = (volume fraction, loss intercept, loss slope). \n",
    "theta_guess = (0.59, 0.5, 0, 0.5, 0)\n",
    "\n",
    "directory = 'data_directory'                    # path where the data is found\n",
    "reference_file = 'ref.txt'                      # name of reference file\n",
    "dark_file = 'dark.txt'                          # name of dark file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer parameters\n",
    "##### Convert raw data into a normalized spectrum and load it\n",
    "All data files for transmission (including reference and dark measurements) should be located in a directory called 'transmission', and all data files for reflection should be located in a directory called 'reflection'. They should be .txt files with two $\\textit{tab-separated}$ columns, where the first is the wavelength and the second is the reflectance or transmittance fraction. Any header information at the top or bottom of the file will be ignored. The reference and dark spectra should have unique names as specified by the user, and the transmission or reflection spectra can have any unspecified name. The code will assume that any file in the data directory other than the reference or dark files is a transmittance or reflectance spectrum. It is expected that the user will include several reflectance/transmittance measurements of the same sample in order to calculate an uncertainty on the data. \n",
    "\n",
    "The data must first be converted into a normalized spectrum with values from 0 to 1, using the reference and dark spectra. This is accomplished using the convert_data() function. The converted data consists of a file with 3 columns: wavelength, normalized intensity, and uncertainty. The uncertainty is the sample standard deviation calculated from all of the reflectance/transmittance data in the directory.\n",
    "\n",
    "The converted data must then be loaded using the load_spectrum() function. This function selects the first reflectance and transmittance data set and returns a Spectrum class object, which containts the relevant spectrum data as a Pandas dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a converted data file for transmittance and reflectance spectra in the directory\n",
    "ifs.convert_data(wavelengths, reference_file, dark_file, os.path.join(directory, 'reflection'))\n",
    "ifs.convert_data(wavelengths, reference_file, dark_file, os.path.join(directory, 'transmission'))\n",
    "\n",
    "# load the converted data file as a Spectrum object\n",
    "spect = ifs.load_spectrum(refl_filepath = os.path.join(directory, 'reflection', 'converted', '0_data_file.txt'), \n",
    "                          trans_filepath = os.path.join(directory, 'transmission', 'converted', '0_data_file.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define sample object\n",
    "This object contains the parameters relevant to the colloidal glass sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp = ifs.Sample(spect.wavelength, particle_radius, thickness, particle_index, matrix_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform inference calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time the calculation, if desired\n",
    "t0 = time.time()\n",
    "\n",
    "# run the markov chain monte carlo calculation to step through different values of \n",
    "# parameters and infer the most likely values\n",
    "walkers = ifs.run_mcmc(spect, samp, nwalkers, nsteps, theta_guess, seed=2)\n",
    "\n",
    "# print the time the calculation took\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "If you want to have these results for later, you can save the markov chains for each parameter as a text file with a desired name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('walkers_chain_vf_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,0])\n",
    "np.savetxt('walkers_chain_refl_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,1])\n",
    "np.savetxt('walkers_chain_refl_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,2])\n",
    "np.savetxt('walkers_chain_trans_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,3])\n",
    "np.savetxt('walkers_chain_trans_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt', walkers.chain[:,:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "##### Load the data\n",
    "Load the data that you saved to a text file previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vf = np.loadtxt('walkers_chain_vf_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "refl_l0 = np.loadtxt('walkers_chain_refl_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "refl_l1 = np.loadtxt('walkers_chain_refl_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "trans_l0 = np.loadtxt('walkers_chain_trans_l0_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')\n",
    "trans_l1 = np.loadtxt('walkers_chain_trans_l1_nwalk' + str(nwalkers) + '_nstep' + str(nsteps) + '.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the traces\n",
    "Plot the values for the loss parameters and the volume fraction at each step of the Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-acdfb2995dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max_l0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max_vf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max_vf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max_l0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l_0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, (ax_vf, ax_refl_l1, ax_refl_l0, ax_trans_l0, ax_trans_l1) = plt.subplots(3)\n",
    "ax_vf.set(ylabel='volume fraction')\n",
    "ax_refl_l0.set(ylabel='reflectance l_0')\n",
    "ax_refl_l1.set(ylabel='reflectance l_1')\n",
    "ax_trans_l0.set(ylabel='transmittance l_0')\n",
    "ax_trans_l1.set(ylabel='transmittance l_1')\n",
    "\n",
    "for i in range(nwalkers):\n",
    "    sns.tsplot(vf[i,:], ax=ax_vf)\n",
    "    sns.tsplot(refl_l0[i,:], ax=ax_refl_l0)\n",
    "    sns.tsplot(refl_l1[i,:], ax=ax_refl_l1)\n",
    "    sns.tsplot(trans_l0[i,:], ax=ax_trans_l0)\n",
    "    sns.tsplot(trans_l1[i,:], ax=ax_trans_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimate the most likely volume fraction\n",
    "\n",
    "The most likely volume fraction is found by calculating the median value of the volume fraction traces after cutting off the burn-in time. We calculate a 68% confidence interval using the built-in numpy percentile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inferred volume fraction is 0.404 + 0.026 - 0.016\n"
     ]
    }
   ],
   "source": [
    "# trim off the burn in time, which we observe from the plots above\n",
    "trim_index = 50\n",
    "vf = np.ndarray.flatten(vf[:,trim_index:])\n",
    "\n",
    "# find the median of the volume fractions of the walkers\n",
    "vf_inferred = np.median(vf)\n",
    "print(\"The inferred volume fraction is {:.3f} + {:.3f} - {:.3f}\".format(vf_inferred,\n",
    "                                                                       np.percentile(vf,84)-vf_inferred,\n",
    "                                                                       vf_inferred - np.percentile(vf,16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
